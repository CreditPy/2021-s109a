{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://github.com/Harvard-IACS/2021-s109a/blob/master/lectures/crest.png?raw=true\"> CS-S109A Introduction to Data Science \n",
    "\n",
    "## Final Exam: COVID-19 Modeling\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Summer 2021**<br/>\n",
    "**Instructors**: Kevin Rader\n",
    "\n",
    "\n",
    "<hr style='height:2px'>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- This final exam is to be completed indivudally.  Do not consult with your peers when working on it (you can aks the teaching staff for clarification questions, including private messages on Ed).\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach. And if a problem specifies a particular library you're required to use that library, and possibly others from the import list.\n",
    "- Please use .head() when viewing data. Do not submit a notebook that is excessively long because output was not suppressed or otherwise limited. \n",
    "\n",
    "**Note: for all problems, it is up to you to decide how to transform the data (standardization, log transformations, etc.).  Be sure you use and interpret theses transformations approporiately.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import statsmodels as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# You are free to use any functions/methods within these packages (BS4, ELI5, and LIME are fine too)\n",
    "# if you would like to use any other, please contact hte teaching staff "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing the recent spread of COVID-19 \n",
    "\n",
    "![](fig/vaccine.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are tasked with using the COVID case and vaccination data across counties presented by the CDC to analyze the recent surge in COVID infections and the association with (amonth other predictors).  You are also tasked with building prediction models to forecast how the disease spread will change based on data from the previous week (and  demographic and other measures.\n",
    "\n",
    "The exam broken into 4 problems:\n",
    "- Problem 1: Data Wrangling and Explorations\n",
    "- Problem 2: Interpretive Linear Regression Modeling\n",
    "- Problem 3: Prediction Modeling\n",
    "- Problem 4: Further Analysis\n",
    "\n",
    "You are provided with four raw data files, and a 5th cleaned file is provided to be used for all EDA and modeling tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables included in each of the four raw data sets are:\n",
    "\n",
    "For 'covid_cases_county.csv' (note: counties show up many times in this dataset: once for each data they report the number of cases):\n",
    "- `date`: the date of the measurement, taken weekly\n",
    "- `county`: county name\n",
    "- `state`: the state in which the county lies\n",
    "- `fips`: the unique Federal Information Processing System (FIPS) codes for the county\n",
    "- `cases`: the cumulative number of confirmed positive cases up to and including that date\n",
    "- `deaths`: the cumulative number of confirmed COVID-related deaths up to and including that date\n",
    "\n",
    "\n",
    "For 'vaccines_county.csv' (note: counties show up many times in this dataset: once for each data they report the number of cases):\n",
    "- `date`: the date of the measurement, taken weekly\n",
    "- `fips`: the unique FIPS code for the county\n",
    "- `fully`: the percent of residents that are fully vaccinated in the county on that date\n",
    "- `dose1`: the percent of residents that have received at least one vaccine dose in the county on that date.\n",
    "\n",
    "For 'masks_county.csv' (note: this is based on a survey conducted by the New York Times in summer of 2020):\n",
    "- `fips`: the unique FIPS code for the county\n",
    "- `never`: the percent of respondents that report they never wore masks in public\n",
    "- `rarely`: the percent of respondents that report they rarely wore masks in public\n",
    "- `sometimes`: the percent of respondents that report they sometimes wore masks in public\t\n",
    "- `frequently`: the percent of respondents that report they frequently wore masks in public\t\n",
    "- `always`: the percent of respondents that report they always wore masks in public\n",
    "\n",
    "For 'demographics_county.csv' (note: these are various measures taken from 2010 to 2020):\n",
    "- `fips`: the unique FIPS code for the county\n",
    "- `population`: total number of residents in the country\t\n",
    "- `hispanic`: the percentage of residents that self-identify as hispanic\n",
    "- `minority`: the percentage of residents that self-identify as a minority group (non-white)\n",
    "- `female`: the percentage of residents that self-identify as female\n",
    "- `unemployed`: the percentage of residents that are unemployed\n",
    "- `income`: the median household income, in thousnads of dollards\n",
    "- `nodegree`: the percentage of residents that report not having graduated high school\n",
    "- `bachelor`: the percentage of residents that report having a college degree\n",
    "- `inactivity`: the percentage of residents that get less than 1 hour of vigorous exercise a week\n",
    "- `obesity`: the percentage of residents that are considered obese based on BMI\n",
    "- `density`: the population density (residents per square mile)\n",
    "- `votergap20`: Biden voting percentage minus Trump voting percentage in the 2020 election\n",
    "- `votergap16`: Clinton voting percentage minus Trump voting percentage in the 2016 election\n",
    "\n",
    "\n",
    "### Data Sources\n",
    "- Vaccinations [here](https://data.cdc.gov/Vaccinations/COVID-19-Vaccinations-in-the-United-States-County/8xkx-amqh).\n",
    "- Cases [here](https://github.com/nytimes/covid-19-data).\n",
    "- Mask Usage [here](https://github.com/nytimes/covid-19-data/tree/master/mask-use).\n",
    "- Demographics [here](https://www.ers.usda.gov/data-products/county-level-data-sets/) \n",
    "- 2020 Election [here](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/VOQCHQ)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 [25pts]: Data Wrangling and Explorations </b></div>\n",
    "\n",
    "**1.1** Load the data sets as follows:\n",
    "- 'covid_cases_county.csv' as `covid_raw` \n",
    "- 'vaccines_county.csv' as `vaccines_raw`\n",
    "- 'masks_county.csv' as `masks`\n",
    "- 'demographics_county.csv' as `demo` \n",
    "\n",
    "**1.2** Create a subset of the `covid_raw` data frame that only contains the measures for 5 dates: June 27 and July 4, 11, 18 and 25.  Do the same for the `vaccines_raw`.  Call these subsets `covid` and `vaccines`, respectively, and print out their dimensions (aka, shapes).\n",
    "\n",
    "**1.3** Determine and print the number of counties that are measured for each time period in `covid` and `vaccines` (do not print out the list of counties, just the number/count).  Comment on what this implies for presence of missing data.\n",
    "\n",
    "**1.4** Process both `covid` and `vaccines` so that each county is represented by a single row in each data frame (rather than having 5 separate rows for each county: 1 for each time period in part 1.2).  Call these new generate Pandas data frames `covid_by_county` and `vaccines_by_county` separately.  Print out the dimensions of each resulting data frame, and view the header of `covid_by_county`.  Note: you should use informative names for the columns in the resulting data frames: for example, `cases_w30` for the cumulative number of cases on July 25 (it's the 30th week of the calendar year).\n",
    "\n",
    "**Hint**: Splitting based on dates and then using `pd.DataFrame.merge` (source)[https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html] could be helpful for this task using the `fips` code as the keys to join on (you should drop any counties that are not measured in all time periods...the default argument for `how` in `pd.DataFrame.merge` will behave this way).\n",
    "\n",
    "**1.5** Merge the 4 data fames (`covid_by_county`, `vaccines_by_county`, `masks`, and `demo`) based on `fips` and save the result as `covid_merged` (you should drop any counties that are not measured in all 4 data frames).  Determine and report how many counties were dropped from `demo` in this process, and view the header of `covid_merged`.\n",
    "\n",
    "**1.6** Use `covid_merged` to calculate the novel case rate (per 1000 residents) for each of the weeks for all of the counties, and save these as 4 new well-named variables in `covid_merged`.  For example, `rate_w30` can mathematically be represented as `1000*(cases_30-cases_29)/population`.  Plot the histogram of the novel case rate in week 29, `rate_w29`, and comment on what you notice.\n",
    "\n",
    "**1.7** We did the steps above (and some other minimal processing) and saved the results in `covid_clean.csv` for you.  Use this data file to answer some exploratory questions and all future analyses: \n",
    "\n",
    "1. Has the overall average case rate increased from week 28 (July 5-11) to week 29 (July 12-18)?  \n",
    "2. Treating the counties as separate and equal observations: in what states did the case rate increase the most?  In what states did the case rate decrease the most (or increse the least)?  List the top 5 for each.  Do you notice any patterns in these states?\n",
    "3. Create and interpret separate visuals to display how the country case rate in week 29 relates to each of the following variables. Interpret what you see (be specific to this domain).\n",
    "\n",
    "    a. The political views in the county (as measured by the votergap in the 2020 election).\n",
    "    \n",
    "    b. The vaccination rate in the county (for week 28) (be sure to throw away the zeros as these represent unreported values).\n",
    "    \n",
    "    c. The population density of the county.\n",
    "    \n",
    "    d. Whether 50% or more of the surveyed residents in the county report that they always wore a mask in public at the time of the survey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** Load the data sets as follows:\n",
    "- 'covid_cases_county.csv' as `covid_raw` \n",
    "- 'vaccines_county.csv' as `vaccines_raw`\n",
    "- 'masks_county.csv' as `masks`\n",
    "- 'demographics_county.csv' as `demo` \n",
    "\n",
    "Print out each of their dimensions (aka, shapes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "covid_raw = pd.read_csv('data/covid_cases_county.csv')\n",
    "vaccines_raw = pd.read_csv('data/vaccines_county.csv')\n",
    "masks = pd.read_csv('data/masks_county.csv')\n",
    "demo = pd.read_csv('data/demographics_county.csv')\n",
    "\n",
    "# print shapes of the datasets\n",
    "print(covid_raw.shape[1],\"total columns in covid_raw, and \",covid_raw.shape[0],\"rows\")\n",
    "print(vaccines_raw.shape[1],\"total columns in vaccines_raw\",vaccines_raw.shape[0],\"rows\")\n",
    "print(masks.shape[1],\"total columns in vaccines_raw\",masks.shape[0],\"rows\")\n",
    "print(demo.shape[1],\"total columns in demo\",demo.shape[0],\"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** Create a subset of the `covid_raw` data frame that only contains the measures for 5 dates: June 27 and July 4, 11, 18 and 25.  Do the same for the `vaccines_raw`.  Call these subsets `covid` and `vaccines`, respectively, and print out their dimensions (aka, shapes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the covid dataset\n",
    "covid_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the covid dataset to selected dates\n",
    "covid = covid_raw.loc[\n",
    "    (covid_raw['date']=='2021-06-27') |\n",
    "    (covid_raw['date']=='2021-07-04') |\n",
    "    (covid_raw['date']=='2021-07-11') |\n",
    "    (covid_raw['date']=='2021-07-18') |\n",
    "    (covid_raw['date']=='2021-07-25')\n",
    "    , :]\n",
    "print(covid.shape[1],\"total columns in covid, and \",covid.shape[0],\"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the vaccine dataset\n",
    "vaccines_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the vaccinces dataset to selected dates\n",
    "vaccines = vaccines_raw.loc[\n",
    "    (vaccines_raw['date']=='2021-06-27') |\n",
    "    (vaccines_raw['date']=='2021-07-04') |\n",
    "    (vaccines_raw['date']=='2021-07-11') |\n",
    "    (vaccines_raw['date']=='2021-07-18') |\n",
    "    (vaccines_raw['date']=='2021-07-25')\n",
    "    , :]\n",
    "print(vaccines.shape[1],\"total columns in vaccinces, and \",vaccines.shape[0],\"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3** Determine and print the number of counties that are measured for each time period in `covid` and `vaccines` (do not print out the list of counties, just the number/count).  Comment on what this implies for presence of missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of counties per day in the covid dataset\n",
    "counties_by_day = covid.groupby('date').agg({'county': 'count',})\n",
    "print(\"Number of counties per day in covid dataset:\")\n",
    "counties_by_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Not all days have the same number of counties. It seems some days have no data for some counties (i.e. missing data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess if there's a one-to-one relationships between counties and FIPS\n",
    "fips_by_day_by_county = covid.groupby(['date','county']).agg({'fips': 'count',})\n",
    "print(\"Number of FIPS per day by county:\")\n",
    "print(fips_by_day_by_county[fips_by_day_by_county['fips'] == 0].head())\n",
    "print(fips_by_day_by_county[fips_by_day_by_county['fips'] > 1].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Some counties have no FIPS, and some counties have multiple FIPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of counties per day in the covid dataset\n",
    "counties_by_day = covid.groupby('date').agg({'fips': 'count',})\n",
    "print(\"Number of the unique Federal Information Processing System (FIPS) codes for the county per day in covid dataset:\")\n",
    "counties_by_day.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of FIPS per day in the vaccines dataset\n",
    "covid_fips_count_by_day = vaccines.groupby('date').agg({'fips': 'count',})\n",
    "print(\"Number of FIPS per day in vaccines dataset:\")\n",
    "covid_fips_count_by_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** We can observe missing data for counties and fips. Not all dates have the same number of counties in the covid dataset. The number of FIPS in the covid and vaccine datasets is also not identical. We'll need dilligence when merging the two datasets. Since some counties have no FIPS in the covid dataset, and since the vaccines dataset doesn't have county data, we will likely not be able to include the counties with missing FIPS in a vaccine analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4** Process both `covid` and `vaccines` so that each county is represented by a single row in each data frame (rather than having 5 separate rows for each county: 1 for each time period in part 1.2).  Call these new generate Pandas data frames `covid_by_county` and `vaccines_by_county` separately.  Print out the dimensions of each resulting data frame, and view the header of `covid_by_county`.  Note: you should use informative names for the columns in the resulting data frames: for example, `cases_w30` for the cumulative number of cases on July 25 (it's the 30th week of the calendar year).\n",
    "\n",
    "**Hint**: Splitting based on dates and then using `pd.DataFrame.merge` (source)[https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html] could be helpful for this task using the `fips` code as the keys to join on (you should drop any counties that are not measured in all time periods...the default argument for `how` in `pd.DataFrame.merge` will behave this way).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the long format into a wide format\n",
    "# reset the index to repivot\n",
    "covid_by_county = covid.reset_index(level=0)\n",
    "# \n",
    "covid_by_county = covid_by_county.pivot_table(index=['fips'], columns='date',\n",
    "                    values=['cases', 'deaths'], aggfunc='sum', margins=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat the column names to one level\n",
    "# create a list of the new column names in the right order\n",
    "new_cols=[('{1} {0}'.format(*tup)) for tup in covid_by_county.columns]\n",
    "\n",
    "# assign it to the dataframe (assuming you named it pivoted\n",
    "covid_by_county.columns= new_cols\n",
    "\n",
    "# resort the index, so you get the columns in the order you specified\n",
    "covid_by_county = covid_by_county.sort_index(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "covid_by_county = covid_by_county.rename(columns = {'2021-06-27 cases': 'cases_w26', \n",
    "                          '2021-07-04 cases': 'cases_w27',\n",
    "                          '2021-07-11 cases': 'cases_w28',\n",
    "                          '2021-07-18 cases': 'cases_w29',\n",
    "                          '2021-07-25 cases': 'cases_w30',\n",
    "                          '2021-06-27 deaths': 'deaths_w26', \n",
    "                          '2021-07-04 deaths': 'deaths_w27',\n",
    "                          '2021-07-11 deaths': 'deaths_w28',\n",
    "                          '2021-07-18 deaths': 'deaths_w29',\n",
    "                          '2021-07-25 deaths': 'deaths_w30',\n",
    "                          }, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the covid dataset\n",
    "covid_by_county.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain the number of columns for future use\n",
    "nr_columns_covid_by_county = covid_by_county.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the long format into a wide format\n",
    "# reset the index to repivot\n",
    "vaccines_by_county = vaccines.reset_index(level=0)\n",
    "# \n",
    "vaccines_by_county = vaccines_by_county.pivot_table(index=['fips'], columns='date',\n",
    "                    values=['fully', 'dose1'], aggfunc='sum', margins=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat the column names to one level\n",
    "# create a list of the new column names in the right order\n",
    "new_cols=[('{1} {0}'.format(*tup)) for tup in vaccines_by_county.columns]\n",
    "\n",
    "# assign it to the dataframe (assuming you named it pivoted\n",
    "vaccines_by_county.columns= new_cols\n",
    "\n",
    "# resort the index, so you get the columns in the order you specified\n",
    "vaccines_by_county = vaccines_by_county.sort_index(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns\n",
    "vaccines_by_county = vaccines_by_county.rename(columns = {\n",
    "                          '2021-06-27 fully': 'fully_w26', \n",
    "                          '2021-07-04 fully': 'fully_w27',\n",
    "                          '2021-07-11 fully': 'fully_w28',\n",
    "                          '2021-07-18 fully': 'fully_w29',\n",
    "                          '2021-07-25 fully': 'fully_w30',\n",
    "                          '2021-06-27 dose1': 'dose1_w26', \n",
    "                          '2021-07-04 dose1': 'dose1_w27',\n",
    "                          '2021-07-11 dose1': 'dose1_w28',\n",
    "                          '2021-07-18 dose1': 'dose1_w29',\n",
    "                          '2021-07-25 dose1': 'dose1_w30',\n",
    "                          }, inplace = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the data with an inner join to remove counties with missing data\n",
    "covid_and_vaccines_by_fips = covid_by_county.merge(vaccines_by_county, on=['fips'])\n",
    "\n",
    "# post merge, split the data back into separate datasets\n",
    "# this will allow both datasets to have an identical set of fips\n",
    "covid_by_county = covid_and_vaccines_by_fips.iloc[:,:nr_columns_covid_by_county]\n",
    "vaccines_by_county = covid_and_vaccines_by_fips.iloc[:,nr_columns_covid_by_county:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the shape of the wide datasets\n",
    "print(covid_by_county.shape[1],\"total columns in covid_by_county, and \",covid_by_county.shape[0],\"rows\")\n",
    "print(vaccines_by_county.shape[1],\"total columns in vaccines_by_county\",vaccines_by_county.shape[0],\"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the covid data\n",
    "covid_by_county.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** As expected, some records were dropped as part of the merge. There are now 3214 rows, instead of 3218. The rows are identical as an inner join merge dropped records where no matching fips were found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5** Merge the 4 data fames (`covid_by_county`, `vaccines_by_county`, `masks`, and `demo`) based on `fips` and save the result as `covid_merged` (you should drop any counties that are not measured in all 4 data frames).  Determine and report how many counties were dropped from `demo` in this process, and view the header of `covid_merged`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retain the original nr. of rows in demo\n",
    "demo_fips_cnt = demo.shape[0]\n",
    "\n",
    "# Merge the datasets\n",
    "covid_merged = covid_by_county.merge(vaccines_by_county, on=['fips'])\n",
    "covid_merged = covid_merged.merge(masks, on=['fips'])\n",
    "covid_merged = covid_merged.merge(demo, on=['fips'])\n",
    "print(\"The number of records dropped from demo is:\", demo_fips_cnt - covid_merged.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6** Use `covid_merged` to calculate the novel case rate (per 1000 residents) for each of the weeks for all of the counties, and save these as 4 new well-named variables in `covid_merged`.  For example, `rate_w30` can mathematically be represented as `1000*(cases_30-cases_29)/population`.  Plot the histogram of the novel case rate in week 29, July 12-18, `rate_w29`, and comment on what you notice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate novel case rates\n",
    "covid_merged['novel_case_rate_w27'] = 1000*(covid_merged['cases_w27'] - \n",
    "                                           covid_merged['cases_w26']) / covid_merged['population']\n",
    "covid_merged['novel_case_rate_w28'] = 1000*(covid_merged['cases_w28'] - \n",
    "                                           covid_merged['cases_w27']) / covid_merged['population']\n",
    "covid_merged['novel_case_rate_w29'] = 1000*(covid_merged['cases_w29'] - \n",
    "                                           covid_merged['cases_w28']) / covid_merged['population']\n",
    "covid_merged['novel_case_rate_w30'] = 1000*(covid_merged['cases_w30'] - \n",
    "                                           covid_merged['cases_w29']) / covid_merged['population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show histograme for week 29\n",
    "novel_case_rate_w29_hist = plt.hist(covid_merged['novel_case_rate_w29'])\n",
    "plt.xlabel(\"Novel case rate per 1000 residents\")\n",
    "plt.ylabel(\"Number of counties\")\n",
    "plt.suptitle(\"Distribution of new cases per 1000 in week 29, by county\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Most counties showed an increase of 1 or 2 cases per thousand in week 29. A few counties had more than 2, going up to an increase of 7 cases per 1000. Close to 500 counties saw a decrease by 1 or w cases, relative to the previous week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.7** We did the steps above (and some other minimal processing) and saved the results in `covid_clean.csv` for you.  Use this data file to answer some exploratory questions and all future analyses: \n",
    "\n",
    "1. Has the overall average case rate increased from week 28 (July 5-11) to week 29 (July 12-18)?  \n",
    "2. Treating the counties as separate and equal observations: in what states did the case rate increase the most?  In what states did the case rate decrease the most (or increse the least)?  List the top 5 for each.  Do you notice any patterns in these states?\n",
    "3. Create and interpret separate visuals to display how the country case rate in week 29 relates to each of the following variables. Interpret what you see (be specific to this domain).\n",
    "\n",
    "    a. The political views in the county (as measured by the votergap in the 2020 election).\n",
    "    \n",
    "    b. The vaccination rate in the county (for week 28) (be sure to throw away the zeros as these represent unreported values).\n",
    "    \n",
    "    c. The population density of the county.\n",
    "    \n",
    "    d. Whether 50% or more of the surveyed residents in the county report that they always wore a mask in public at the time of the survey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the cleaned dataset\n",
    "covid_clean = pd.read_csv('data/covid_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Has the overall average case rate increased from week 28 (July 5-11) to week 29 (July 12-18)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot novel cases per 1000 for w29\n",
    "novel_case_rate_w29_hist = plt.hist(covid_clean['rate_w29']*1000)\n",
    "plt.xlabel(\"Novel case rate per 1000 residents\")\n",
    "plt.ylabel(\"Number of counties\")\n",
    "plt.suptitle(\"Distribution by county of new cases per 1000 in week 29\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_covid_increase = covid_clean['rate_w29'].mean()\n",
    "print(\"Average covid increase per 1000 in week 29:\", average_covid_increase *1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**: The histogram shows that overall rate of covid cases has increased for all counties, on average 0.66 per thousand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Treating the counties as separate and equal observations: in what states did the case rate increase the most? In what states did the case rate decrease the most (or increse the least)? List the top 5 for each. Do you notice any patterns in these states?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the counties with the highest rate increase\n",
    "covid_clean.sort_values('rate_w29', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the counties with the highest rate increase\n",
    "covid_clean.sort_values('rate_w29', ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** At first glance it looks like the northern states had the lowest increase in cases, and the mid-country southern states had the highest increase in cases in week 29."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create and interpret separate visuals to display how the country case rate in week 29 relates to each of the following variables. Interpret what you see (be specific to this domain).**\n",
    "\n",
    "**a. The political views in the county (as measured by the votergap in the 2020 election).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot novel cases per 1000 for w29 as a function of votergap\n",
    "# show the logaritmic view to distribute the scatter more evenly\n",
    "plt.scatter(covid_clean['votergap20'],np.log(covid_clean['rate_w29']*1000))\n",
    "plt.xlabel(\"Votergap in the 2020 election\")\n",
    "plt.ylabel(\"Log of novel case rate per 1000 residents\")\n",
    "plt.suptitle(\"Distribution of novel cases in week 29 by votergap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Without controlling for confounding factors, there doesn't seem to be a pattern between votergap in the 2020 elections and the covid novel case rate in week 29."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b. The vaccination rate in the county (for week 28) (be sure to throw away the zeros as these represent unreported values).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_clean_nonzero_vac = covid_clean[covid_clean['fully_w28']!=0]\n",
    "print(\"Nr of counties with unreported vaccination numbers in week 28:\",covid_clean.shape[0]-\n",
    "                                                                      covid_clean_nonzero_vac.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot novel cases per 1000 for w29 as a function of vaccination in the previous week\n",
    "# show the logaritmic view to distribute the scatter more evenly\n",
    "plt.scatter(covid_clean_nonzero_vac['fully_w28'],np.log(covid_clean_nonzero_vac['rate_w29']*1000))\n",
    "plt.xlabel(\"Vaccination rates\")\n",
    "plt.ylabel(\"Log of novel case rate per 1000 residents\")\n",
    "plt.suptitle(\"Distribution of novel cases in week 29 by vaccination rates in week 28\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Without controlling for confounding factors, there doesn't seem to be a pattern between vaccination rates in week 28 and the covid novel case rate in week 29."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c. The population density of the county.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot novel cases per 1000 for w29 as a function of votergap\n",
    "# show the logaritmic view to distribute the scatter more evenly\n",
    "plt.scatter(np.log(covid_clean['density']),np.log(covid_clean['rate_w29']*1000))\n",
    "plt.xlabel(\"Population\")\n",
    "plt.ylabel(\"Log of novel case rate per 1000 residents\")\n",
    "plt.suptitle(\"Distribution of novel cases in week 29 by population density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Without controlling for confounding factors, there doesn't seem to be a pattern between population density and the covid novel case rate in week 29."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d. Whether 50% or more of the surveyed residents in the county report that they always wore a mask in public at the time of the survey.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to mask wearing higher than 50%\n",
    "covid_clean_mask_adoption_above_50pc = covid_clean[covid_clean['always']>=50]\n",
    "covid_clean_mask_adoption_below_50pc = covid_clean[covid_clean['always']<50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot novel cases per 1000 for w29 as a function of votergap\n",
    "# show the logaritmic view to distribute the scatter more evenly\n",
    "novel_case_rate_w29_hist_above_50_masked = plt.hist(covid_clean_mask_adoption_above_50pc['rate_w29']*1000, alpha=0.5, label='Above 50% always wears mask')\n",
    "novel_case_rate_w29_hist_below_50_masked = plt.hist(covid_clean_mask_adoption_below_50pc['rate_w29']*1000, alpha=0.5, label='Below 50% always wears mask')\n",
    "plt.xlabel(\"Novel case rate per 1000 residents\")\n",
    "plt.ylabel(\"Number of counties\")\n",
    "plt.legend()\n",
    "plt.suptitle(\"Distribution by county of new cases per 1000 in week 29\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Without controlling for confounding factors, there seems to be rather unpronounced pattern between aobve 50 percent mask adoption and the increase in covid cases per thousand. For 100 counties, the number of cases seems 1 or 2 cases higher per thousand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 [35pts]: Regression modeling \n",
    "\n",
    "**2.1** Fit a linear regression model to predict `rate_w29` (which represent the rate of new cases in the week of July 12-18) from `rate_w28` (July 5-11). Report the 95% confidence intervals for the coefficients, and carefully interpret the coefficients (including their statistical significances).  What does this model suggest about whether the rate of COVID infection increased from week 28 to week 29?\n",
    "\n",
    "\n",
    "**2.2** Fit a linear regression model to predict `rate_w29` from `rate_w28` and `votergap20` along with the interaction between the two.  Interpret the coefficient estimates carefully (no need to mention significances).\n",
    "\n",
    "\n",
    "**2.3** Create a scatterplot of `rate_w29` vs. `rate_w28`.  Add 3 separate predicted lines from your model in 2.2 to this scatterplot: the predicted line from the model in 2.2 for counties...\n",
    "    1. where Biden was favored by 50 percentage points.\n",
    "    2. where Biden and Trump were equal\n",
    "    3. where Trump was favored by 50 percentage points.\n",
    "Interpret what you see.\n",
    "\n",
    "\n",
    "**2.4** Fit a linear regression model to assess the overall association of vaccination rate (`fully_w28`) on `rate_w29`.  Carefully interpret the results (including the statistical significance).  \n",
    "\n",
    "\n",
    "**2.5** Many counties have the value zero for `fully_w28` which really represents a missing/unreported value for vaccinationr rate.  Comment on the effect of ignoring this issue can have on the intepretations and inferences in the model in 2.4.  What would be a better way of handling this issue?\n",
    "\n",
    "\n",
    "**2.6** What factors could be confounded (whether mesured here or not) with the result seen in the model from 2.3 (list up to 3)?  Fit an appropriate linear model that controls for as many of these factors as possible (for those that are measured in this data set). Interpret the coefficient estimates from this model and compare to the results from 2.4.\n",
    "\n",
    "**2.7** What major issue could arise if you fit a model to predict `rate_w29` from `rate_w28` and `rate_w27` (or from `fully_w28` and `fully_w27`) in a linear regression model?  Suggest and explain the use of two different approaches to account for this: one approach should be based on modeling and one approach should be based on feature engineering/variable transformations (not PCA). \n",
    "\n",
    "**2.8** The test set has a response variable that is `rate_w30`.  How would you use your models to predict `rate_w29` in this section in order to predict `rate_w30` instead?  Explain.  What could go wrong in this modification?\n",
    "\n",
    "**Hint**: what should be the predictors to predict `rate_w30` instead of `rate_w29`? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1** Fit a linear regression model to predict `rate_w29` (which represent the rate of new cases in the week of July 12-18) from `rate_w28` (July 5-11). Report the 95% confidence intervals for the coefficients, and carefully interpret the coefficients (including their statistical significances).  What does this model suggest about whether the rate of COVID infection increased from week 28 to week 29?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot novel cases per 1000 for w29 as a function of w29\n",
    "plt.scatter(covid_clean['rate_w28'],covid_clean['rate_w29'])\n",
    "plt.xlabel(\"Increase in week 28\")\n",
    "plt.ylabel(\"Increasein week 29\")\n",
    "plt.suptitle(\"Graph 2.1.1 Correlation between week 28 and week 29 covid case growth rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Graph 2.1.1 would indicate there is a positive linear relationship between the rate of increase in week 28 and the rate of increase in week 29. This is quite intuive as one would assume a certain level of momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape the data for regression with one series\n",
    "rate_w29 = covid_clean['rate_w29'].to_numpy().reshape(-1,1)\n",
    "rate_w28 = covid_clean['rate_w28'].to_numpy().reshape(-1,1)\n",
    "\n",
    "# add intercept\n",
    "OLS_X = sm.tools.add_constant(rate_w28)\n",
    "\n",
    "# fit the model on the training data\n",
    "OLSModel = OLS(rate_w29,OLS_X).fit()\n",
    "# print(\"Statmodels results: \\n\",OLSModel.params,sep=\"\")\n",
    "OLSModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the coefficients confidence intervals from the model\n",
    "confidence_intervals = OLSModel.conf_int(alpha=0.05, cols=None)\n",
    "pvalues = OLSModel.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing values from the summary table\n",
    "print(\"The 95% confidence interval for the intercept is:\", confidence_intervals[0][0], \"-\", confidence_intervals[0][1])\n",
    "print(\"The statistical significance (p-value) for the intercept is:\", pvalues[0])\n",
    "print(\"The 95% confidence interval for the slope is:\", confidence_intervals[1][0], \"-\", confidence_intervals[1][1])\n",
    "print(\"The statistical significances (p-value) for the slope is:\", pvalues[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot novel cases per 1000 for w29 as a function of w29\n",
    "plt.scatter(covid_clean['rate_w28'],covid_clean['rate_w29'])\n",
    "plt.xlabel(\"Increase in week 28\")\n",
    "plt.ylabel(\"Increase in week 29\")\n",
    "i=0.0004       # intercept\n",
    "s=0.6603        # slope\n",
    "x=np.linspace(-0.005,0.03,20)      # from 1 to 10, by 50\n",
    "plt.plot(x, s*x + i, c = 'red')    \n",
    "plt.suptitle(\"Graph 2.1.2 Correlation between week 28 and week 29 covid case growth rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** The statistical significance for both coefficients is 0. This means the probability that we would find these coefficients if the null hypothesis were true, is zero. As such, the coefficients are considered statistically significant.\n",
    "The intercept coefficient is very close to 0. Most of the effect is therefore between rate_28 and rate_29.\n",
    "The slope coefficient is estimated at 0.6603: for every increase in rate_28 for a county, we - on average - expect rate_29 rate to increase by 0.6603. As such - as the coefficient is less than one - this suggests the rate of COVID infection DEcreased from week 28 to week 29.\n",
    "When graphing the relationship however, it seems reasonable to conclude that the slope is underestimated, probably due to outliers on the bottom right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2** Fit a linear regression model to predict `rate_w29` from `rate_w28` and `votergap20` along with the interaction between the two.  Interpret the coefficient estimates carefully (no need to mention significances).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add intercept, taking into account both regressors\n",
    "covid_clean['rate_w28*votergap20'] = covid_clean['rate_w28']*covid_clean['votergap20']\n",
    "OLS_x_train = sm.tools.add_constant(covid_clean[['rate_w28','votergap20', 'rate_w28*votergap20']])\n",
    "\n",
    "# limit the target variable to pickup count for the dataset\n",
    "y_train = covid_clean['rate_w29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model on the training data\n",
    "OLSModel = OLS(y_train,OLS_x_train).fit()\n",
    "print(\"Statmodels results: \\n\",OLSModel.params,sep=\"\")\n",
    "\n",
    "OLSModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot novel cases per 1000 for w29 as a function of w29\n",
    "plt.scatter(covid_clean['rate_w28'],covid_clean['rate_w29'])\n",
    "plt.xlabel(\"Increase in week 28\")\n",
    "plt.ylabel(\"Increase in week 29\")\n",
    "i=0.0001       # intercept\n",
    "s=1.1899       # slope\n",
    "x=np.linspace(-0.005,0.03,20)      # from 1 to 10, by 50\n",
    "plt.plot(x, s*x + i, c = 'red')    \n",
    "plt.suptitle(\"Graph 2.1.3 Correlation between week 28 and week 29 covid case growth rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the interaction\n",
    "votergap20_median = covid_clean.votergap20.median()\n",
    "covid_clean['gap20_med'] = covid_clean.votergap20 > votergap20_median\n",
    "plt.scatter(covid_clean['rate_w28'],covid_clean['rate_w29'], c=covid_clean['gap20_med'], alpha = 0.5)\n",
    "# plot below median votergap slope\n",
    "x=np.linspace(-0.005,0.03,20)      # from 1 to 10, by 50\n",
    "i=0.0001       # intercept\n",
    "s=1.1899       # slope below median\n",
    "plt.plot(x, s*x + i, c = 'yellow', label='Below votergap median')   \n",
    "# plot above median votergap slope\n",
    "s= 1.1899 + 0.0102 * votergap20_median\n",
    "plt.plot(x, s*x + i, c = 'purple', label='Above votergap median')\n",
    "plt.xlabel(\"Increase in week 28\")\n",
    "plt.ylabel(\"Increasein week 29\")\n",
    "plt.suptitle(\"Graph 2.1.4 Correlation between w28 and w29 covid growth rate by votergap\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing all rows and columns when displaying pandas info \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the outliers\n",
    "print(\"Votergap outliers:\")\n",
    "covid_clean.loc[:,['county','votergap20']][covid_clean['rate_w28'] > 0.01]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** \n",
    "Coefficient interpretation:\n",
    "- At 0 rate_w28 and 0 votergap20, we expect mpg to be 0.0001\n",
    "- For every 1 unit increase in rate_w28 (the increase in covid cases per 1000, relative to the previous week), rate_w29 increases by 1.1899 (holding votergap20 at 0)\n",
    "- For every 1 unit increase in rate_w28, rate_w29 changes by 1.1899 + votergap20 * 0.0102 (where votergap20 is not 0)\n",
    "- For every 1 unit increase in votergap20, rate_w29 changes by -4.804e-06 (holding rate_28 at 0)\n",
    "- For every 1 unit increase in votergap20, rate_w29 changes by -4.804e-06 + rate_28 * 0.0102 (where rate_28 is not 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** While the coefficient for votergap is relatively small, there is a material effect when controlling for votergap and the interaction with rate_w28. After controlling for votergap20 (and the interaction), the coefficient for rate_w28 is almost 1.19. This indicates that for every increase in rate_w28, rate_29 increased by 20% more.\n",
    "After controlling for the confounding factors, the regression graph 2.1.3 also looks more reasonable.\n",
    "The interaction variable indicates how different the slope for rate_w28 is as voter gap changes. As median votergap20 is negative, for each one change in voter gap, the slope for rate_w28 decreases by 0.01. This is  illustrated in graph 2.1.4 in purple. The graph also demonstrates how the purple line may be pushed down by outliers for counties Franklin, Powder River, and Loving, counties where Trump significantly outperformed Biden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3** Create a scatterplot of `rate_w29` vs. `rate_w28`.  Add 3 separate predicted lines from your model in 2.2 to this scatterplot: the predicted line from the model in 2.2 for counties...\n",
    "    1. where Biden was favored by 50 percentage points.\n",
    "    2. where Biden and Trump were equal\n",
    "    3. where Trump was favored by 50 percentage points.\n",
    "Interpret what you see.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot various predicted lines for three votergap scenarios\n",
    "\n",
    "\n",
    "# We can see the interaction by cutting one of the terms in the interaction along it’s median,\n",
    "# and then plotting the response variable against the other variable in the interacting pair\n",
    "votergap20 = covid_clean.votergap20.median()\n",
    "covid_clean['gap20_med'] = covid_clean.votergap20 > votergap20_median\n",
    "plt.scatter(covid_clean['rate_w28'],covid_clean['rate_w29'], c=covid_clean['gap20_med'], alpha = 0.5)\n",
    "\n",
    "# line specs\n",
    "x=np.linspace(-0.005,0.03,20) \n",
    "i=0.0001       # intercept\n",
    "\n",
    "# plot where Biden was favored by 50 percentage points\n",
    "votergap20 = 50\n",
    "s = 1.1899 + 0.0102 * votergap20       # slope as a function of votergap20\n",
    "plt.plot(x, s*x + i, c = 'blue', label='Biden was favored by 50 percentage points')   \n",
    "\n",
    "# plot where Biden and Trump were equal\n",
    "votergap20 = 0\n",
    "s = 1.1899 + 0.0102 * votergap20       # slope as a function of votergap20\n",
    "plt.plot(x, s*x + i, c = 'purple', label='Biden and Trump were equal')\n",
    "\n",
    "# plot where Trump was favored by 50 percentage points.\n",
    "votergap20 = -50\n",
    "s = 1.1899 + 0.0102 * votergap20       # slope as a function of votergap20\n",
    "plt.plot(x, s*x + i, c = 'red', label='Trump was favored by 50 percentage points')   \n",
    "\n",
    "# Clean up plot\n",
    "plt.xlabel(\"Increase in week 28\")\n",
    "plt.ylabel(\"Increasein week 29\")\n",
    "plt.suptitle(\"Comparison of predicted slopes by votergap\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** We can observe a lower predicted increase in counties where Trump was favored by more than 50 percentage points, and a higher predicted increase in counties where Biden was favored by more than 50 percentage points. Where Biden and Trump were equal, the week 29 increase lies in between."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4** Fit a linear regression model to assess the overall association of vaccination rate (`fully_w28`) on `rate_w29`.  Carefully interpret the results (including the statistical significance).  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape the data for regression with one series\n",
    "rate_w29 = covid_clean['rate_w29'].to_numpy().reshape(-1,1)\n",
    "fully_w28 = covid_clean['fully_w28'].to_numpy().reshape(-1,1)\n",
    "\n",
    "# add intercept\n",
    "OLS_X = sm.tools.add_constant(fully_w28)\n",
    "\n",
    "# fit the model on the training data\n",
    "OLSModel = OLS(rate_w29,OLS_X).fit()\n",
    "# print(\"Statmodels results: \\n\",OLSModel.params,sep=\"\")\n",
    "OLSModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the coefficients confidence intervals from the model\n",
    "confidence_intervals = OLSModel.conf_int(alpha=0.05, cols=None)\n",
    "pvalues = OLSModel.pvalues\n",
    "\n",
    "# printing values from the summary table\n",
    "print(\"The 95% confidence interval for the intercept is:\", confidence_intervals[0][0], \"-\", confidence_intervals[0][1])\n",
    "print(\"The statistical significance (p-value) for the intercept is:\", pvalues[0])\n",
    "print(\"The 95% confidence interval for the slope is:\", confidence_intervals[1][0], \"-\", confidence_intervals[1][1])\n",
    "print(\"The statistical significances (p-value) for the slope is:\", pvalues[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** The statistical significance for both coefficients is near 0. This means the probability that we would find these coefficients if the null hypothesis were true, is zero. As such, the coefficients are considered statistically significant.\n",
    "The intercept coefficient is 0.0009. When fully vaccination rate in week 28 is zero, we therefore expect the increse in covid cases in week 29 to be 0.0009.\n",
    "The slope coefficient is estimated at roughly -7e-06. As such, for every increase in vaccination rate for a county, we - on average - expect rate_29 to decease by 7 in a million."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5** Many counties have the value zero for `fully_w28` which really represents a missing/unreported value for vaccination rate.  Comment on the effect of ignoring this issue can have on the intepretations and inferences in the model in 2.4.  What would be a better way of handling this issue?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Since fully_w28 at zero really represents a missing / unreported value for vaccination rate, zero does not seem to be a reasonable value. First, the absence of data can reduce statistical power (the probability that the test will reject the null hypothesis when it is false). Second, the lost data can cause bias in the estimation of parameters. \n",
    "A better way of handling this, would be to impute the missing / unreported values with a reasonable value. One way to impute a reasonable value, could be to use the average vaccination rate of neighbouring counties. Alternatively, we could use a modeling technique such as regression to impute the missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.6** What factors could be confounded (whether measured here or not) with the result seen in the model from 2.3 (list up to 3)?  Fit an appropriate linear model that controls for as many of these factors as possible (for those that are measured in this data set). Interpret the coefficient estimates from this model and compare to the results from 2.4.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Amongst many possible confounding factors, it seems reasonable that the results in 2.3 could be confounded by mask wearing habits, vaccination rates, and population density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all the non-numeric columns\n",
    "covid_clean_num_only = covid_clean.drop(['date','county', 'state', 'gap20_med'],axis=1) \n",
    "\n",
    "# removing the data for previous weeks as they are likely to be highly collinear with the values of week 28\n",
    "covid_clean_num_only = covid_clean_num_only.drop(['cases_w26','deaths_w26', 'fully_w26', 'dose1_w26'],axis=1)\n",
    "covid_clean_num_only = covid_clean_num_only.drop(['cases_w27','deaths_w27', 'fully_w27', 'dose1_w27', 'rate_w27'],axis=1)\n",
    "covid_clean_num_only = covid_clean_num_only.drop(['cases_w28'],axis=1)\n",
    "# removing the data from week 29 and week 30 as this wouldn't be known at prediction time\n",
    "covid_clean_num_only = covid_clean_num_only.drop(['cases_w29','deaths_w29', 'fully_w29', 'dose1_w29'],axis=1)\n",
    "covid_clean_num_only = covid_clean_num_only.drop(['cases_w30','deaths_w30', 'fully_w30', 'dose1_w30', 'rate_w30'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning out a couple of records with non-numeric values in votergap16\n",
    "orig_nr_rows = covid_clean_num_only.shape[0]\n",
    "covid_clean_num_only = covid_clean_num_only.loc[:,:][covid_clean_num_only['votergap16']!='#VALUE!']\n",
    "print(\"Number of rows removed by cleaning up non-numeric values:\", orig_nr_rows - covid_clean_num_only.shape[0])\n",
    "\n",
    "#convert votergap16 to dtype float\n",
    "covid_clean_num_only['votergap16'] = covid_clean_num_only['votergap16'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add interaction variables between rate_28 and the mask variables\n",
    "# drop the previous interaction variables\n",
    "\n",
    "covid_clean_num_only = covid_clean_num_only.drop(['rate_w28*votergap20'],axis=1) \n",
    "# for column in ['never','rarely','sometimes','frequently', 'always', 'density', 'votergap20']:\n",
    "for column in covid_clean_num_only.columns:\n",
    "    if column != 'rate_w28' and column != 'rate_w29':\n",
    "        covid_clean_num_only[str(column) + '*' + 'rate_w28'] = covid_clean_num_only[column] * covid_clean_num_only['rate_w28']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #standardize the features\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# column_names = covid_clean_num_only.columns\n",
    "# scale_transformer = MinMaxScaler(copy=True).fit(covid_clean_num_only)\n",
    "# covid_clean_num_only = pd.DataFrame(scale_transformer.transform(covid_clean_num_only))\n",
    "# covid_clean_num_only.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manage the target variable\n",
    "X_train = covid_clean_num_only.loc[:, covid_clean_num_only.columns != 'rate_w29']\n",
    "y_train = covid_clean_num_only.rate_w29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use backward selection to prune the predictors\n",
    "X = pd.DataFrame(X_train)\n",
    "# set p-value minimum to retain predictor\n",
    "cutoff = 0.05\n",
    "\n",
    "for i in np.arange(X.shape[1]):\n",
    "    # add the constant as statsmodel doesn't do that for us\n",
    "    OLS_x_train = sm.tools.add_constant(X)\n",
    "    # fit the model with the remaining predictors\n",
    "    OLSModel = OLS(y_train,OLS_x_train).fit()\n",
    "    # remove the predictor with the highest p-value\n",
    "    highest_non_const_p_value = np.max(OLSModel.pvalues[1:])\n",
    "    if highest_non_const_p_value > cutoff:\n",
    "        highest_non_const_p_value_name = np.argmax(OLSModel.pvalues[1:])\n",
    "        print(\"Predictor#:\", highest_non_const_p_value_name, \n",
    "              \"with associated p-value of\" ,\n",
    "              highest_non_const_p_value, \n",
    "              \"is being removed\")\n",
    "        X = X.drop(highest_non_const_p_value_name,axis=1)\n",
    "        X.reset_index\n",
    "\n",
    "OLSModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments:** \n",
    "- We added a significant set of possibly confounding factors. The effect of full vaccination in week28, however, remains quite similar: in 2.4, the coeffient for fully_w28 is -6.699e-06. After adding additional predictors, the coefficient is -6.058e-06. Full vaccination therefore continues to predict a slightly lower rate for week 29. \n",
    "- We can observe that the coefficient of rate_w28 has increased significantly, from 1.1899 in 2.3 to 2.9137. \n",
    "- Most predictors in the dataset have been retained after backward selection, including confounders such as population, minority, unemployment rate, education factors, health factors and voter gaps. Notably, the density and \"always\" mask wearing predictors were eliminated due to high p-value. This is likely the case because of multicollinearity with other predictors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.7** What major issue could arise if you fit a model to predict `rate_w29` from `rate_w28` and `rate_w27` (or from `fully_w28` and `fully_w27`) in a linear regression model?  Suggest and explain the use of two different approaches to account for this: one approach should be based on modeling and one approach should be based on feature engineering/variable transformations (not PCA). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Rate_w28 and Rate_w27 will likely be highly correlated: where there's been material change in cases in one direction, we should expect a similar change the week after. Adding both feauters, therefore will increase a multicollinearity problem, making coefficients, confidence intervals and p-values unreliable. One solution (as illustrated above) is to use a predictor selection method (e.g., forward or backward selection). \n",
    "To reduce the risk of multicollinearity, it is recommended to standardize features. (@Devisch. Is this true? Should we have standardized the features for all solutions above?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.8** The test set has a response variable that is `rate_w30`.  How would you use your models to predict `rate_w29` in this section in order to predict `rate_w30` instead?  Explain.  What could go wrong in this modification?\n",
    "\n",
    "**Hint**: what should be the predictors to predict `rate_w30` instead of `rate_w29`? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Our model is hard coded to predict rate_w29 from previous weeks' data. As such, if we wanted to predict rate_w30, we'd want to use e.g., rate_29 as a predictor (not rate_w28).\n",
    "One solution is to keep the columns names as-is, but to shift the data by one week. We'd, for example, replace rate_w28 with rate_w29 data, rate_w27 data with rate_w28 data, rate_w26 data with rate_w27 data. We'd perform a similar operation for the other weekly metrics ('cases_w26','deaths_w26', 'fully_w26', 'dose1_w26')\n",
    "\n",
    "Covid patterns, however, change continuously. @Devisch. It's be great to show this. As such, this approach would not hold over time. A better approach, would be to do refit the model with the more recent data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 [30pts]: Prediction modeling \n",
    "\n",
    "**3.1** Fit a well-tuned lasso model to predict `rate_w29` from the following set of predictors (along with all 2-way interactions among the main effects and all 2nd and 3rd order polynomial terms):\n",
    "\n",
    "`['rate_w28','rate_w27','dose1_w28','hispanic','minority','female','unemployed', 'income','nodegree','bachelor','inactivity','obesity','density','cancer','votergap20']`\n",
    "\n",
    "Report and explain the best choice of $\\lambda$ (a visual can help with this), your estimate of out-of-sample $R^2$, along with the number of coefficients that shrunk exactly to zero (or numerically zero) and the number that are non-zero.\n",
    "\n",
    "**3.2** Plot the trajectory curves of the main effects `['rate_w28','rate_w27','fully_w28','votergap20']` from this model: the estimates of the $\\beta$ coefficients as a function of $\\lambda$.  Interpret what you notice.\n",
    "\n",
    "**3.3** Fit a well-tuned random forest model to predict `rate_w29` from the predictors listed in 3.1.  Report your choice of the tuning parameters and briefly justify your choices (a visual or table may be helpful for this).  Provide an estimate of out-of-sample $R^2$.  Note: do not go to crazy with the number of options for the parameters you are tuning...choose a set of values that are reasonable.\n",
    "\n",
    "**3.4** Interpret the relationship between `rate_w29` and `dose1_w28` from the random forest model in 3.3.  Is there any evidence of interactive effects in this model involving `dose1_w28`?  How do you know?  Provide a reasonable visual (or a few visuals) to help you with these tasks and interpret what you see. \n",
    "\n",
    "**3.5** Fit a well-tuned boosting model to predict `rate_w29` from the predictors listed in 3.1.  Report your best choice of the tuning parameters and briefly justify your choice (a visual or table may be helpful for this).  Provide an estimate of out-of-sample $R^2$.  Note: again, do not go to crazy with the number of options for the parameters you are tuning...choose a set of values that are reasonable.\n",
    "\n",
    "**3.6** Improve upon your favorite/best predictive model from 3.1, 3.3, or 3.5, by including other provided feature, by doing feature engineering, or by doing variable removal/selection.  Explain your choices.  Provide an estimate of out-of-sample $R^2$. \n",
    "\n",
    "**3.7** Evaluate your models from 3.1, 3.3, 3.5, and 3.6 on the test set (this will take some work...refer back to 2.8) using $R^2$.  How do these model's $R^2$ in test compare to the out-of-sample $R^2$ when tuning?  Explain whether this is surprising or not?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1** Fit a well-tuned lasso model to predict `rate_w29` from the following set of predictors (along with all 2-way interactions among the main effects and all 2nd and 3rd order polynomial terms):\n",
    "\n",
    "`['rate_w28','rate_w27','dose1_w28','hispanic','minority','female','unemployed', 'income','nodegree','bachelor','inactivity','obesity','density','cancer','votergap20']`\n",
    "\n",
    "Report and explain the best choice of $\\lambda$ (a visual can help with this), your estimate of out-of-sample $R^2$, along with the number of coefficients that shrunk exactly to zero (or numerically zero) and the number that are non-zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descriptions = ['Poly, interact and lasso', 'Random forest']\n",
    "idx = pd.Index(model_descriptions, name='Regression method')\n",
    "\n",
    "# prepare a dataframe to represent rates for each model\n",
    "model_comparison_df = pd.DataFrame(\n",
    "    index=idx,\n",
    "    columns=['training accuracy', 'test accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart from clean data\n",
    "covid_clean = pd.read_csv('data/covid_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downselect columns\n",
    "# not including 'cancer'\n",
    "columns = ['rate_w28','rate_w27','dose1_w28','hispanic','minority','female','unemployed', \n",
    "            'income','nodegree','bachelor','inactivity','obesity','density','votergap20']\n",
    "X = covid_clean.loc[:,columns]\n",
    "y = pd.DataFrame(covid_clean.loc[:,['rate_w29']])\n",
    "X = X.reindex()\n",
    "y = y.reindex()\n",
    "\n",
    "# add a week 30 version with an identical split for easy model testing on never seen target data\n",
    "y_w30_test_lasso, y_w30_test_lasso = train_test_split(pd.DataFrame(covid_clean.loc[:,['rate_w30']]), test_size=0.2, random_state = 109)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare out of time data\n",
    "covid_clean_w30 = covid_clean.copy()\n",
    "latest_week = 29\n",
    "features = []\n",
    "weeks = [26,27,28]\n",
    "week_dependent_features = ['cases','deaths', 'fully', 'dose1', 'rate']\n",
    "\n",
    "for week in weeks:\n",
    "    for column in week_dependent_features:\n",
    "        curr_feature = column + '_w' + str(week)\n",
    "        next_feature = column + '_w' + str(week + 1)\n",
    "        features.append(curr_feature)\n",
    "        covid_clean_w30[curr_feature] = covid_clean[next_feature]\n",
    "\n",
    "X_w30 = covid_clean.loc[:,columns]\n",
    "y_w30 = pd.DataFrame(covid_clean.loc[:,['rate_w30']])\n",
    "X_w30 = X_w30.reindex()\n",
    "y_w30 = y_w30.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note how the number of rows for X_train and X_test is different, but number of columns is identical\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"X_train shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_poly_features(dataset, degree, columns):\n",
    "    \"\"\"\n",
    "    :param dataset: Your data\n",
    "    :param degree: Max degree\n",
    "    :return: Augmented DataFrame\n",
    "    \"\"\"\n",
    "    # walk through the columns for which to add polynomials\n",
    "    for column in columns:\n",
    "        # create 2+ degree polynomials\n",
    "        for polynomial in range(degree):\n",
    "            # ignore polynomials with exponent 0 and 1\n",
    "            polynomial = polynomial + 2\n",
    "            if polynomial <= degree:\n",
    "                # create the new columns\n",
    "                dataset[str(column) + \"_\" + str(polynomial)] = dataset[column] ** polynomial\n",
    "    poly_dataset = dataset\n",
    "    return poly_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add second and third polynomials\n",
    "X_train = add_poly_features(X_train, 3, columns)\n",
    "X_test = add_poly_features(X_test, 3, columns)\n",
    "# take a quick look at the dataset\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_interaction(df, columns):\n",
    "    # create a copy of the columns and dataframes to avoid unintentionally changing the original set\n",
    "    interact_left = columns.copy()\n",
    "    interact_right = columns.copy()\n",
    "    result_df = df.copy()\n",
    "\n",
    "    # create interaction features for all the requested columns\n",
    "    for left in interact_left:\n",
    "        # avoid multiplying by oneself, or producing the same column twice\n",
    "        interact_right.remove(left)\n",
    "        for right in interact_right:\n",
    "            # create an interaction column by multiplying the numbers\n",
    "            if left != right:\n",
    "                result_df[str(left) + '_*_' + str(right)] = df[left] * df[right]\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = build_interaction(X_train, columns)\n",
    "X_test = build_interaction(X_test, columns)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "# X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize the features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "column_names = X_train.columns\n",
    "scale_transformer = MinMaxScaler(copy=True).fit(X_train)\n",
    "X_train = pd.DataFrame(scale_transformer.transform(X_train))\n",
    "X_test = pd.DataFrame(scale_transformer.transform(X_test))\n",
    "X_train.columns = column_names\n",
    "X_test.columns = column_names\n",
    "\n",
    "\n",
    "scale_transformer = MinMaxScaler(copy=True).fit(y_train)\n",
    "y_train = pd.DataFrame(scale_transformer.transform(y_train))\n",
    "y_test = pd.DataFrame(scale_transformer.transform(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare w_30\n",
    "# # add a week 30 version with an identical split for easy model testing on never seen target data\n",
    "# y_w30_test_lasso, y_w30_test_lasso = train_test_split(pd.DataFrame(covid_clean.loc[:,['rate_w30']]), test_size=0.2, random_state = 109)\n",
    "# # train accuracy\n",
    "#         y_train_pred = covid_lasso.predict(X_train) \n",
    "#         best_train_score = r2_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a quick look at the standardized dataset\n",
    "# Note that, as expected, all features are scaled between 0 and 1\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put y_train in the expected format\n",
    "y_train = y_train.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the locations for columns of interest (for later use)\n",
    "rate_w28_loc = X_train.columns.get_loc('rate_w28')\n",
    "rate_w27_loc = X_train.columns.get_loc('rate_w27')\n",
    "dose1_w28_loc = X_train.columns.get_loc('dose1_w28')\n",
    "votergap20_loc = X_train.columns.get_loc('votergap20')\n",
    "\n",
    "rate_w28_coefs = []\n",
    "rate_w27_coefs = []\n",
    "dose1_w28_coefs = []\n",
    "votergap20_coefs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions for ease of use\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# choose from a range of lambdas (lasso penalties)\n",
    "lambdas = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "# initialize variables\n",
    "best_accuracy = -1\n",
    "best_model = None\n",
    "accuracies = []\n",
    "models = []\n",
    "\n",
    "# experiment with different lambdas\n",
    "for c in lambdas:\n",
    "    #@Devisch should we use cross validation instead?\n",
    "    covid_lasso = Lasso(alpha=c, max_iter=100000, fit_intercept=True)\n",
    "    covid_lasso.fit(X_train, y_train)\n",
    "    y_hat_test = covid_lasso.predict(X_test)\n",
    "    cur_accuracy = r2_score(y_test.to_numpy(), y_hat_test)\n",
    "\n",
    "    # adding accuracy to a list in case we want to show how accuracy changes with lambda\n",
    "    accuracies.append(cur_accuracy)\n",
    "    models.append(covid_lasso)\n",
    "\n",
    "    # track how specific coefficients change as a function of lambda\n",
    "    rate_w28_coefs.append(covid_lasso.coef_[rate_w28_loc])\n",
    "    rate_w27_coefs.append(covid_lasso.coef_[rate_w27_loc])\n",
    "    dose1_w28_coefs.append(covid_lasso.coef_[dose1_w28_loc])\n",
    "    votergap20_coefs.append(covid_lasso.coef_[votergap20_loc])\n",
    "    \n",
    "    # retain the best model\n",
    "    if cur_accuracy > best_accuracy:\n",
    "        best_accuracy = cur_accuracy\n",
    "        best_lasso_model = covid_lasso\n",
    "        best_lambda = c\n",
    "            \n",
    "        # train accuracy\n",
    "        y_train_pred = covid_lasso.predict(X_train) \n",
    "        best_train_score = r2_score(y_train, y_train_pred)\n",
    "        \n",
    "        \n",
    "\n",
    "print(\"Best lambda is:\",best_lambda )\n",
    "print(\"Best test accuracy is:\",best_accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambdas,accuracies)\n",
    "plt.xlabel(\"Lambda\")\n",
    "plt.ylabel(\"Test R squared\")\n",
    "plt.title(\"Test R squared\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Note how only small values of lambda produce a reasonable R squared score. Once the score reaches 1%, test score plummet. The penality is too high, and all coefficients become zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a dataframe with the coefficients\n",
    "coef_pd = pd.DataFrame(np.transpose([best_lasso_model.coef_]),\n",
    "            columns = [\"best_lasso_model_coeff\"], index=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of NON-zero coefficients:\", coef_pd[:][coef_pd['best_lasso_model_coeff']!=0].shape[0])\n",
    "print(\"The number of zero coefficients:\", coef_pd[:][coef_pd['best_lasso_model_coeff']==0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** Note how only five coefficients are non-zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all the non-zero coefficients\n",
    "coef_pd[:][coef_pd['best_lasso_model_coeff']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add best tree to comparison table\n",
    "model_comparison_df.loc['Poly, interact and lasso','test accuracy'] = best_accuracy\n",
    "model_comparison_df.loc['Poly, interact and lasso','training accuracy'] = best_train_score\n",
    "# model_comparison_df.loc['Poly, interact and lasso','w30 accuracy'] = w30_accuracy\n",
    "\n",
    "# display the rates by model in percentage format\n",
    "model_comparison_df.style.format({\n",
    "    'training accuracy': '{:,.1%}'.format,\n",
    "    'test accuracy': '{:,.1%}'.format,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import Lasso\n",
    "# lasso_alpha0001 = Lasso(alpha=0.0001,fit_intercept=True,max_iter=100000).fit(X_train , y_train)\n",
    "# lasso_alpha001 = Lasso(alpha=0.001,fit_intercept=True,max_iter=100000).fit(X_train , y_train)\n",
    "# lasso_alpha01 = Lasso(alpha=0.01,fit_intercept=True,max_iter=100000).fit(X_train , y_train)\n",
    "# lasso_alpha1 = Lasso(alpha=1,fit_intercept=True`a,max_iter=1000).fit(X_train , y_train)\n",
    "# lasso_alpha10 = Lasso(alpha=10,fit_intercept=True,max_iter=1000).fit(X_train , y_train)\n",
    "# lasso_alpha100 = Lasso(alpha=100,fit_intercept=True,max_iter=1000).fit(X_train , y_train)\n",
    "\n",
    "# # Add everything to a table\n",
    "# coef_pd = pd.DataFrame(np.transpose([lasso_alpha0001.coef_,lasso_alpha001.coef_,lasso_alpha01.coef_,\n",
    "#                           lasso_alpha1.coef_,lasso_alpha10.coef_,lasso_alpha100.coef_]),\n",
    "#             columns = [\"lasso_alpha0001\",\"lasso_alpha001\",\"lasso_alpha01\",\"lasso_alpha1\",\n",
    "#                        \"lasso_alpha10\",\"lasso_alpha100\",], index=X_train.columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2** Plot the trajectory curves of the main effects `['rate_w28','rate_w27','fully_w28','votergap20']` from this model: the estimates of the $\\beta$ coefficients as a function of $\\lambda$.  Interpret what you notice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lambdas, rate_w28_coefs, label=\"rate_w28\")\n",
    "plt.plot(lambdas, rate_w27_coefs, label=\"rate_w27\")\n",
    "plt.plot(lambdas, dose1_w28_coefs, label=\"dose1_w28\")\n",
    "plt.plot(lambdas, votergap20_coefs, label=\"votergap20\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** The coefficients for all predictors except votergap have been shrunk to zero fo all values of lambda. Only the smallest lambda retains a predictor: votergap20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3** Fit a well-tuned random forest model to predict `rate_w29` from the predictors listed in 3.1.  Report your choice of the best tuning parameters and briefly justify your choice (a visual or table may be helpful for this).  Provide an estimate of out-of-sample $R^2$.  Note: do not go to crazy with the number of options for the parameters you are tuning...choose a set of values that are reasonable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart from clean data\n",
    "covid_clean = pd.read_csv('data/covid_clean.csv')\n",
    "# downselecting columns\n",
    "# not including 'cancer'\n",
    "columns = ['rate_w28','rate_w27','dose1_w28','hispanic','minority','female','unemployed', \n",
    "            'income','nodegree','bachelor','inactivity','obesity','density','votergap20']\n",
    "X = covid_clean.loc[:,columns]\n",
    "y = pd.DataFrame(covid_clean.loc[:,['rate_w29']])\n",
    "# X_train = X_train.reindex()\n",
    "# y_train = y_train.reindex()\n",
    "\n",
    "# split dataset in train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 109)\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a dataframe to represent rates for each model\n",
    "random_forest_comparison_df = pd.DataFrame(\n",
    "    columns=['training accuracy', 'test accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "random_forest_train_score = -1\n",
    "random_forest_test_score = -1\n",
    "depth_option = 7\n",
    "tree_nr_options = [10,20,50,100]\n",
    "depth_options = [5, 10, 15]\n",
    "max_features_list = [2,5,10,len(X_train.columns)]\n",
    "row_number = 0\n",
    "\n",
    "# go through all the depth options we want to explore\n",
    "for depth_option in depth_options:\n",
    "    # go through all the options for nr of trees we want to explore\n",
    "    for ntrees in tree_nr_options:\n",
    "        # buld ntrees trees\n",
    "        for max_features in max_features_list:\n",
    "            estimators = []\n",
    "            R2s_train = []\n",
    "            R2s_test = []\n",
    "            y_hats_test = np.zeros((X_test.shape[0], ntrees))\n",
    "            randomtree = RandomForestRegressor(max_depth=depth_option, max_features = max_features)\n",
    "            # bootstap the training set\n",
    "            boot_x, boot_y = resample(X_train, y_train)\n",
    "            \n",
    "            # fit and test the model\n",
    "            estimators = np.append(estimators,randomtree.fit(boot_x, boot_y))\n",
    "            R2s_train = np.append(R2s_train,randomtree.score(X_train, y_train))\n",
    "            R2s_test = np.append(R2s_test,randomtree.score(X_test, y_test))\n",
    "            \n",
    "            # Add rates to dataframe for clear comparison \n",
    "            curr_tree_descr = str(ntrees) + ' bagged trees w/ depth ' + str(depth_option) + \" and max_features \" + str(max_features)\n",
    "            random_forest_comparison_df.loc[curr_tree_descr,'training accuracy'] = np.mean(R2s_train)\n",
    "            \n",
    "            # accuracy scores on test set\n",
    "            random_forest_comparison_df.loc[curr_tree_descr,'test accuracy'] = np.mean(R2s_test)\n",
    "            \n",
    "            row_number = row_number + 1\n",
    "            # retain the best scores\n",
    "            if np.mean(R2s_test) > random_forest_test_score:\n",
    "                random_forest_test_score = np.mean(R2s_test)\n",
    "                random_forest_train_score = np.mean(R2s_train)\n",
    "                best_tree_nr = ntrees\n",
    "                best_depth = depth_option\n",
    "                best_max_features = max_features\n",
    "                best_RF_model = randomtree\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the best test scores\n",
    "random_forest_comparison_df.sort_values('test accuracy', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** We're choosing the model with the best test accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best tree number is:\", best_tree_nr)\n",
    "print(\"The best tree depth is:\", best_depth)\n",
    "print(\"The best max_features is:\", best_max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add best tree to comparison table\n",
    "model_comparison_df.loc['Random forest','training accuracy'] = random_forest_train_score\n",
    "model_comparison_df.loc['Random forest','test accuracy'] = random_forest_test_score\n",
    "\n",
    "# display the rates by model in percentage format\n",
    "model_comparison_df.style.format({\n",
    "    'training accuracy': '{:,.1%}'.format,\n",
    "    'test accuracy': '{:,.1%}'.format,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4** Interpret the relationship between `rate_w29` and `dose1_w28` from the random forest model in 3.3.  Is there any evidence of interactive effects in this model involving `dose1_w28`?  How do you know?  Provide a reasonable visual (or a few visuals) to help you with these tasks and interpret what you see. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data frame of means to do the prediction\n",
    "means1 = X_train.mean(axis = 0)\n",
    "means_df = (means1.to_frame()).transpose()\n",
    "\n",
    "# Do the prediction at all observed dose1_w28\n",
    "doses = np.arange(np.min(X_train['dose1_w28']),np.max(X_train['dose1_w28']))\n",
    "means_df  = pd.concat([means_df]*doses.size,ignore_index=True)\n",
    "means_df['dose1_w28'] = doses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means1.to_frame().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots at means\n",
    "yhat_rf = best_RF_model.predict(means_df)\n",
    "plt.scatter(X_train['dose1_w28'],y_train)\n",
    "plt.plot(means_df['dose1_w28'],yhat_rf,color=\"red\")\n",
    "plt.title(\"Predicted rate_w29 vs. dose1_w28 from RF in train\")\n",
    "plt.xlabel(\"Dose1_w28\")\n",
    "plt.ylabel(\"Rate_w29\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots for all observations.  And then averaged\n",
    "yhat_rfs = []\n",
    "for i in range(0,X_train.shape[0]):\n",
    "    obs = X_train.iloc[i,:].to_frame().transpose()\n",
    "    obs_df  = pd.concat([obs]*doses.size,ignore_index=True)\n",
    "    obs_df['dose1_w28'] = doses\n",
    "    yhat_rf = best_RF_model.predict(obs_df)\n",
    "    yhat_rfs.append(yhat_rf)\n",
    "    plt.plot(obs_df['dose1_w28'],yhat_rf,color='blue',alpha=0.05)\n",
    "\n",
    "plt.plot(obs_df['dose1_w28'],np.mean(yhat_rfs, axis=0),color='red',linewidth=2);\n",
    "    \n",
    "# plt.ylim(0,1)\n",
    "plt.xlabel(\"One vaccination received rate in week 28\")\n",
    "plt.ylabel(\"Case rate change week 29\")\n",
    "plt.title(\"Predicted rate_w29 vs. dose1_28 from RF in train for all observations\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** We can observe that in the randomforest model dose1_w28 does not have much of an effect on predicted values: the red (average) line is flat. We also plotted the full range of dose1_w28 for each observation in the training set. We can observe that the graph shape for dose1_w28 varies only marginally between the observations. We can therefore conclude that limited interaction effects exist between dose1_w28 and other predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5** Fit a well-tuned boosting model to predict `rate_w29` from the predictors listed in 3.1.  Report your best choice of the tuning parameters and briefly justify your choice (a visual or table may be helpful for this).  Provide an estimate of out-of-sample $R^2$.  Note: again, do not go to crazy with the number of options for the parameters you are tuning...choose a set of values that are reasonable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "boosts = []\n",
    "boostfts = []\n",
    "depths = [1, 2, 3, 4,5,6,7]\n",
    "# build boost models with base estimators of different depths\n",
    "for base_depth in depths:\n",
    "    boost = AdaBoostRegressor( base_estimator = DecisionTreeRegressor(max_depth = base_depth),\n",
    "                              n_estimators=100)\n",
    "    boosts.append(boost)\n",
    "\n",
    "\n",
    "    # Fit on the entire data\n",
    "    boostfit = boost.fit(X_train,y_train)\n",
    "    boostfts.append(boostfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy by estimator for different base depths\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "for base_depth in depths:\n",
    "    plt.plot(list(boosts[base_depth -1].staged_score(X_test,y_test)),\n",
    "             label=\"Test accuracy, depth \" + str(base_depth), color = \"green\", alpha = base_depth/8)\n",
    "    plt.plot(list(boosts[base_depth -1].staged_score(X_train,y_train)),\n",
    "             label=\"Train accuracy, depth \" + str(base_depth), color = \"red\", alpha = base_depth/8)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy as a function of iterations\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(boosts[3].staged_score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we've visually assessed initial depth equal to three to be the best option\n",
    "best_depth = 3\n",
    "best_boost = boosts[best_depth -1]\n",
    "train_list = list(best_boost.staged_score(X_train,y_train))\n",
    "test_list = list(best_boost.staged_score(X_test,y_test))\n",
    "\n",
    "# assess which iteration is best\n",
    "index_best_accuracy = test_list.index(max(test_list))\n",
    "print(\"The iteration with the best accuracy is:\", index_best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add best tree to comparison table\n",
    "model_comparison_df.loc['Adaboost','training accuracy'] = train_list[index_best_accuracy]\n",
    "model_comparison_df.loc['Adaboost','test accuracy'] = test_list[index_best_accuracy]\n",
    "\n",
    "# display the rates by model in percentage format\n",
    "model_comparison_df.style.format({\n",
    "    'training accuracy': '{:,.1%}'.format,\n",
    "    'test accuracy': '{:,.1%}'.format,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** The best adaboost model seems to be a smiple one with initial depth equal to three. As we increase the initial depth more, the model becomes overfit: test scores do not improve, but train scores do. We also note that the best model has very few iterations. This indicates we lack important variables: with the data availalble, the model cannot improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add best tree to comparison table\n",
    "model_comparison_df.loc['Adaboost','training accuracy'] = train_list[index_best_accuracy]\n",
    "model_comparison_df.loc['Adaboost','test accuracy'] = test_list[index_best_accuracy]\n",
    "\n",
    "# display the rates by model in percentage format\n",
    "model_comparison_df.style.format({\n",
    "    'training accuracy': '{:,.1%}'.format,\n",
    "    'test accuracy': '{:,.1%}'.format,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.6** Improve upon your favorite/best predictive model from 3.1, 3.3, or 3.5, by including other provided feature, by doing feature engineering, or by doing variable removal/selection.  Explain your choices.  Provide an estimate of out-of-sample $R^2$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart from clean data\n",
    "covid_clean = pd.read_csv('data/covid_clean.csv')\n",
    "# downselecting columns\n",
    "# not including 'cancer'\n",
    "# columns = ['rate_w28','rate_w27','dose1_w28','hispanic','minority','female','unemployed', \n",
    "#             'income','nodegree','bachelor','inactivity','obesity','density','votergap20']\n",
    "\n",
    "# drop non numeric columns\n",
    "covid_clean = covid_clean.drop(['date','county', 'fips','state'],axis=1) \n",
    "\n",
    "\n",
    "# removing the data from week 29 and week 30 as this wouldn't be known at prediction time\n",
    "covid_clean = covid_clean.drop(['cases_w29','deaths_w29', 'fully_w29', 'dose1_w29'],axis=1)\n",
    "covid_clean = covid_clean.drop(['cases_w30','deaths_w30', 'fully_w30', 'dose1_w30', 'rate_w30'],axis=1)\n",
    "\n",
    "\n",
    "# cleaning out a couple of records with non-numeric values in votergap16\n",
    "orig_nr_rows = covid_clean.shape[0]\n",
    "covid_clean = covid_clean.loc[:,:][covid_clean['votergap16']!='#VALUE!']\n",
    "print(\"Number of rows removed by cleaning up non-numeric values:\", orig_nr_rows - covid_clean.shape[0])\n",
    "\n",
    "#convert votergap16 to dtype float\n",
    "covid_clean['votergap16'] = covid_clean['votergap16'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(covid_clean.loc[:,['rate_w29']])\n",
    "X = covid_clean.drop(['rate_w29'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# columns = ['rate_w28','rate_w27', 'minority','female'\n",
    "#            ,'dose1_w28','hispanic','unemployed', \n",
    "#             'income','nodegree','bachelor','inactivity','obesity','density','votergap20'\n",
    "#             ,'sometimes', 'frequently'\n",
    "#           ]\n",
    "# X = X.loc[:,columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = pd.Index.tolist(X.columns)\n",
    "# # add second and third polynomials\n",
    "\n",
    "# X = add_poly_features(X, 5, columns)\n",
    "\n",
    "# # take a quick look at the dataset\n",
    "# print(X.shape)\n",
    "# X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = build_interaction(X, columns)\n",
    "# print(X.shape)\n",
    "# # X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset in train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 109)\n",
    "\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a dataframe to represent rates for each model\n",
    "random_forest_comparison_df = pd.DataFrame(\n",
    "    columns=['training accuracy', 'test accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "random_forest_train_score = -1\n",
    "random_forest_test_score = -1\n",
    "depth_option = 7\n",
    "tree_nr_options = [10,20,50,100]\n",
    "depth_options = [5, 10, 15]\n",
    "# max_features_list = [2,5,10,len(X_train.columns)]\n",
    "max_features_list = [2,len(X_train.columns)]\n",
    "\n",
    "row_number = 0\n",
    "\n",
    "# go through all the depth options we want to explore\n",
    "for depth_option in depth_options:\n",
    "    # go through all the options for nr of trees we want to explore\n",
    "    for ntrees in tree_nr_options:\n",
    "        # buld ntrees trees\n",
    "        for max_features in max_features_list:\n",
    "            estimators = []\n",
    "            R2s_train = []\n",
    "            R2s_test = []\n",
    "            y_hats_test = np.zeros((X_test.shape[0], ntrees))\n",
    "            randomtree = RandomForestRegressor(max_depth=depth_option, max_features = max_features)\n",
    "            # bootstap the training set\n",
    "            boot_x, boot_y = resample(X_train, y_train)\n",
    "            \n",
    "            # fit and test the model\n",
    "            estimators = np.append(estimators,randomtree.fit(boot_x, boot_y))\n",
    "            R2s_train = np.append(R2s_train,randomtree.score(X_train, y_train))\n",
    "            R2s_test = np.append(R2s_test,randomtree.score(X_test, y_test))\n",
    "            \n",
    "            # Add rates to dataframe for clear comparison \n",
    "            curr_tree_descr = str(ntrees) + ' bagged trees w/ depth ' + str(depth_option) + \" and max_features \" + str(max_features)\n",
    "            random_forest_comparison_df.loc[curr_tree_descr,'training accuracy'] = np.mean(R2s_train)\n",
    "            \n",
    "            # accuracy scores on test set\n",
    "            random_forest_comparison_df.loc[curr_tree_descr,'test accuracy'] = np.mean(R2s_test)\n",
    "            \n",
    "            row_number = row_number + 1\n",
    "            # retain the best scores\n",
    "            if np.mean(R2s_test) > random_forest_test_score:\n",
    "                random_forest_test_score = np.mean(R2s_test)\n",
    "                random_forest_train_score = np.mean(R2s_train)\n",
    "                best_tree_nr = ntrees\n",
    "                best_depth = depth_option\n",
    "                best_max_features = max_features\n",
    "                best_RF_all_Feature_model = randomtree\n",
    "                \n",
    "                \n",
    "# Print out the best test scores\n",
    "random_forest_comparison_df.sort_values('test accuracy', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add best tree to comparison table\n",
    "model_comparison_df.loc['RF all features','training accuracy'] = random_forest_train_score\n",
    "model_comparison_df.loc['RF all features','test accuracy'] = random_forest_test_score\n",
    "\n",
    "# display the rates by model in percentage format\n",
    "model_comparison_df.style.format({\n",
    "    'training accuracy': '{:,.1%}'.format,\n",
    "    'test accuracy': '{:,.1%}'.format,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install eli5\n",
    "# !pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "#permutation importance for the random forest\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "seed = 42\n",
    "\n",
    "perm = PermutationImportance(best_RF_all_Feature_model,random_state=seed,n_iter=10).fit(X_test, y_test)\n",
    "eli5.show_weights(perm,feature_names=X.columns.tolist())\n",
    "#eli5.explain_weights(perm, feature_names = X_train.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:** We did not improve upon the random forest model by adding the remaining features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.7** Evaluate your models from 3.1, 3.3, 3.5, and 3.6 on the test set (this will take some work...refer back to 2.8) using $R^2$.  How do these model's $R^2$ in test compare to the out-of-sample $R^2$ when tuning?  Explain whether this is surprising or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 [10pts]: Going further\n",
    "\n",
    "**4.1** Use all of the useable variables in `demo` and `masks` to create clusters of observations based on the $K$-means clustering approach.  Be sure to carefully select a reasonable choice for $K$.  Explain your choice (a visual may help with this).\n",
    "\n",
    "**4.2** Use your created clusters and incorporate them as predictor(s) into a linear regression model to assess whether the relationships you measured in the model from 2.6 depend on cluster type.  Comment on what you notice.  Determine whether out-of-sample $R^2$ has improved using this model (in comparison to the model from 2.6) based on 5-fold CV.\n",
    "\n",
    "**4.3: BONUS** Find data online to improve the prediction accuracy of your best model. Be sure to cite your source of your data and the approach you took into incorporating these new data.  Note: this is only worth up to 3 bonus points, so do not spend too much effor on this part over improving ealrier parts of the exam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.1** Use all of the useable variables in `demo` and `masks` to create clusters of observations based on the $K$-means clustering approach.  Be sure to carefully select a reasonable choice for $K$.  Explain your choice (a visual may help with this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2** Use your created clusters and incorporate them as predictor(s) into a linear regression model to assess whether the relationships you measured in the model from 2.6 depend on cluster type.  Comment on what you notice.  Determine whether out-of-sample $R^2$ has improved using this model (in comparison to the model from 2.6) based on 5-fold CV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.3: BONUS** Find data online to improve the prediction accuracy of your best model. Be sure to cite your source of your data and the approach you took into incorporating these new data.  Note: this is only worth up to 3 bonus points, so do not spend too much effor on this part over improving ealrier parts of the exam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# your code here\n",
    "######\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
